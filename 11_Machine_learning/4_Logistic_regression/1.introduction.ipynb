{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8900c4d",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "**Logistic Regression** is a **supervised machine learning algorithm** used for **classification problems**.  \n",
    "Despite its name, it is a **classification model**, not a regression model.  \n",
    "\n",
    "It predicts the **probability** that an input belongs to a particular class  \n",
    "(e.g., Yes/No, Spam/Not Spam, 0/1).\n",
    "\n",
    "\n",
    "\n",
    "### Why We Cannot Use Linear Regression for Classification\n",
    "\n",
    "Using **Linear Regression** for classification tasks is not ideal for several reasons:\n",
    "\n",
    "1. **Output Range**  \n",
    "   Linear Regression can produce values outside the range of **0 to 1**, which are not valid probabilities.  \n",
    "   Logistic Regression, on the other hand, uses the **logistic (sigmoid) function** to ensure that outputs are constrained within this range.\n",
    "\n",
    "2. **Non-linearity**  \n",
    "   The relationship between the independent variables and the probability of the dependent variable is often **non-linear**.  \n",
    "   Logistic Regression captures this non-linearity through the logistic function.\n",
    "\n",
    "\n",
    "\n",
    "### Logistic Regression Model and Sigmoid Function\n",
    "\n",
    "The logistic regression model outputs probability using the **sigmoid function**:\n",
    "\n",
    "$$\n",
    "h_\\theta(x) = \\frac{1}{1 + e^{-(z)}}\n",
    "$$\n",
    "\n",
    "**Output meaning:**\n",
    "\n",
    "$\n",
    "\\text{If } h_\\theta(x) \\geq 0.5 \\Rightarrow \\text{Class 1}\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{If } h_\\theta(x) < 0.5 \\Rightarrow \\text{Class 0}\n",
    "$\n",
    "\n",
    "\n",
    "where\n",
    "z=θ₀ + θ₁x₁ + θ₂x₂ + ... + θₙxₙ\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2eedc5",
   "metadata": {},
   "source": [
    "### cost function\n",
    "The cost function used in Logistic Regression is the **Log Loss (Cross-Entropy Loss)**, defined as: \n",
    "$$\n",
    "J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\theta(x^{(i)})) \\right]\n",
    "$$\n",
    "where:\n",
    "- \\( m \\) is the number of training examples\n",
    "- \\( y^{(i)} \\) is the actual label for the \\( i^{th} \\) training example\n",
    "- \\( h_\\theta(x^{(i)}) \\) is the predicted probability for the \\( i^{th} \\) training example    \n",
    "- \\( \\theta \\) represents the model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bed4c4",
   "metadata": {},
   "source": [
    "### Performance Metrics\n",
    "Common performance metrics for evaluating Logistic Regression models include:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 Score\n",
    "- F beta Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971ed205",
   "metadata": {},
   "source": [
    "* Precision: The ratio of true positive predictions to the total predicted positives.  \n",
    "  It measures the accuracy of positive predictions.  \n",
    "  example: spem email detection. Reduce false positive.It means not marking important email as spam.\n",
    "  $$\n",
    "  \\text{Precision} = \\frac{TP}{TP + FP}\n",
    "  $$\n",
    "* Recall: The ratio of true positive predictions to the total actual positives.  \n",
    "  It measures the ability of the model to find all relevant cases.  \n",
    "  Example: disease detection. Reduce false negative. It means not missing any diseased patient.\n",
    "  $$\n",
    "  \\text{Recall} = \\frac{TP}{TP + FN}\n",
    "  $$\n",
    "* F1 Score: The harmonic mean of precision and recall.  \n",
    "  It provides a balance between precision and recall.  \n",
    "  $$\n",
    "  \\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "  $$\n",
    "* F beta Score: A generalization of the F1 Score that allows weighting recall more than precision (or vice versa) based on the value of beta.  \n",
    " F beta score= (precision* recall)/(precision + recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0ad3ae",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
